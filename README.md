# Curso de Azure y Databricks con PySpark

## Módulo 1: Introducción a Azure y Databricks

### Introducción a la Computación en la Nube y Azure

#### Teoría:
- [Conceptos básicos de la computación en la nube](./Modulo1_Introduccion_Azure_Databricks/Introduccion_Computacion_Nube_Azure/Conceptos_basicos_computacion_nube.md)
- [Beneficios de usar la nube](./Modulo1_Introduccion_Azure_Databricks/Introduccion_Computacion_Nube_Azure/Beneficios_usar_nube.md)
- [Introducción a Microsoft Azure](./Modulo1_Introduccion_Azure_Databricks/Introduccion_Computacion_Nube_Azure/Introduccion_Microsoft_Azure.md)
- [Modelos de servicio en la nube (IaaS, PaaS, SaaS)](./Modulo1_Introduccion_Azure_Databricks/Introduccion_Computacion_Nube_Azure/Modelos_servicio_nube.md)
- [Modelos de implementación en la nube (pública, privada, híbrida)](./Modulo1_Introduccion_Azure_Databricks/Introduccion_Computacion_Nube_Azure/Modelos_implementacion_nube.md)

#### Laboratorio:
- [Navegar por el portal de Azure y familiarizarse con los servicios disponibles](./Modulo1_Introduccion_Azure_Databricks/Introduccion_Computacion_Nube_Azure/Laboratorio_portal_Azure.md)

### Conceptos Básicos de Databricks

#### Teoría:
- [¿Qué es Databricks?](./Modulo1_Introduccion_Azure_Databricks/Conceptos_Basicos_Databricks/Que_es_Databricks.md)
- [Historia y evolución](./Modulo1_Introduccion_Azure_Databricks/Conceptos_Basicos_Databricks/Historia_evolucion_Databricks.md)
- [Beneficios y casos de uso](./Modulo1_Introduccion_Azure_Databricks/Conceptos_Basicos_Databricks/Beneficios_casos_uso_Databricks.md)
- [Integración de Databricks con otros servicios de Azure](./Modulo1_Introduccion_Azure_Databricks/Conceptos_Basicos_Databricks/Integracion_Azure.md)

#### Laboratorio:
- [Explorar la interfaz de usuario de Databricks](./Modulo1_Introduccion_Azure_Databricks/Conceptos_Basicos_Databricks/Laboratorio_interfaz_Databricks.md)
- [Crear y configurar un workspace de Azure Databricks](./Modulo1_Introduccion_Azure_Databricks/Conceptos_Basicos_Databricks/Laboratorio_crear_workspace.md)

### Configuración Inicial de Azure

#### Teoría:
- [Navegación en el portal de Azure](./Modulo1_Introduccion_Azure_Databricks/Configuracion_Inicial_Azure/Navegacion_portal_Azure.md)
- [Gestión de recursos en Azure (grupos de recursos, políticas de costos)](./Modulo1_Introduccion_Azure_Databricks/Configuracion_Inicial_Azure/Gestion_recursos_Azure.md)

#### Laboratorio:
- [Configurar un recurso de Databricks en Azure](./Modulo1_Introduccion_Azure_Databricks/Configuracion_Inicial_Azure/Laboratorio_configuracion_Databricks.md)
- [Familiarizarse con las opciones de configuración y seguridad del workspace](./Modulo1_Introduccion_Azure_Databricks/Configuracion_Inicial_Azure/Laboratorio_seguridad_workspace.md)

### Creación de un Workspace de Azure Databricks

#### Teoría:
- [Crear un recurso de Databricks en Azure](./Modulo1_Introduccion_Azure_Databricks/Creacion_Workspace_Azure_Databricks/Crear_recurso_Databricks_Azure.md)
- [Configuración básica del workspace](./Modulo1_Introduccion_Azure_Databricks/Creacion_Workspace_Azure_Databricks/Configuracion_basica_workspace.md)
- [Configuración avanzada del workspace (redes, seguridad)](./Modulo1_Introduccion_Azure_Databricks/Creacion_Workspace_Azure_Databricks/Configuracion_avanzada_workspace.md)

#### Laboratorio:
- [Crear un nuevo clúster en Azure Databricks](./Modulo1_Introduccion_Azure_Databricks/Creacion_Workspace_Azure_Databricks/Laboratorio_crear_cluster.md)
- [Configurar parámetros básicos del clúster (tipo de máquina, autoescalado, etc.)](./Modulo1_Introduccion_Azure_Databricks/Creacion_Workspace_Azure_Databricks/Laboratorio_configuracion_basica_cluster.md)
- [Configurar parámetros avanzados del clúster (seguridad, redes)](./Modulo1_Introduccion_Azure_Databricks/Creacion_Workspace_Azure_Databricks/Laboratorio_configuracion_avanzada_cluster.md)

## Módulo 2: Fundamentos de Apache Spark y PySpark

### Introducción a Apache Spark

#### Teoría:
- [Historia de Apache Spark](./Modulo2_Fundamentos_Apache_Spark_PySpark/Introduccion_Apache_Spark/Historia_Apache_Spark.md)
- [Arquitectura de Spark](./Modulo2_Fundamentos_Apache_Spark_PySpark/Introduccion_Apache_Spark/Arquitectura_Spark.md)
- [Componentes de Spark](./Modulo2_Fundamentos_Apache_Spark_PySpark/Introduccion_Apache_Spark/Componentes_Spark.md)
- [Ciclo de vida de una aplicación Spark](./Modulo2_Fundamentos_Apache_Spark_PySpark/Introduccion_Apache_Spark/Ciclo_vida_aplicacion_Spark.md)

#### Laboratorio:
- [Crear un clúster de Spark en Databricks](./Modulo2_Fundamentos_Apache_Spark_PySpark/Introduccion_Apache_Spark/Laboratorio_crear_cluster_Spark.md)
- [Ejecutar un script básico de Spark para contar líneas en un archivo de texto](./Modulo2_Fundamentos_Apache_Spark_PySpark/Introduccion_Apache_Spark/Laboratorio_script_basico_Spark.md)
- [Monitorización de tareas y debugging en Spark](./Modulo2_Fundamentos_Apache_Spark_PySpark/Introduccion_Apache_Spark/Laboratorio_monitorizacion_Spark.md)

#### Recursos:
- [Anexo de recursos para los laboratorios](./Modulo2_Fundamentos_Apache_Spark_PySpark/Introduccion_Apache_Spark/Anexo_de_recursos.md)

- [Anexo configuración de almacenamiento](./Modulo2_Fundamentos_Apache_Spark_PySpark/Introduccion_Apache_Spark/Anexo_de_configuracion_almacenamiento.md)


### Introducción a PySpark

#### Teoría:
- [¿Qué es PySpark?](./Modulo2_Fundamentos_Apache_Spark_PySpark/Introduccion_PySpark/Que_es_PySpark.md)
- [Instalación y configuración de PySpark](./Modulo2_Fundamentos_Apache_Spark_PySpark/Introduccion_PySpark/Instalacion_configuracion_PySpark.md)
- [Comparativa entre PySpark y otros frameworks de procesamiento de datos](./Modulo2_Fundamentos_Apache_Spark_PySpark/Introduccion_PySpark/Comparativa_PySpark_frameworks.md)

#### Laboratorio:
- [Configurar un notebook de Databricks para usar PySpark](./Modulo2_Fundamentos_Apache_Spark_PySpark/Introduccion_PySpark/Laboratorio_configurar_notebook_PySpark.md)
- [Ejecutar operaciones básicas con RDDs (Resilient Distributed Datasets)](./Modulo2_Fundamentos_Apache_Spark_PySpark/Introduccion_PySpark/Laboratorio_operaciones_basicas_RDDs.md)
- [Creación y manipulación de DataFrames](./Modulo2_Fundamentos_Apache_Spark_PySpark/Introduccion_PySpark/Laboratorio_creacion_manipulacion_DataFrames.md)

#### Recursos:
- [Anexo generador de recursos](./Modulo2_Fundamentos_Apache_Spark_PySpark/Introduccion_PySpark/generador_de_recursos.md)

### DataFrames y SQL en PySpark

#### Teoría:
- [Creación y manipulación de DataFrames](./Modulo2_Fundamentos_Apache_Spark_PySpark/DataFrames_SQL_PySpark/Creacion_Manipulacion_DataFrames.md)
- [Operaciones básicas](./Modulo2_Fundamentos_Apache_Spark_PySpark/DataFrames_SQL_PySpark/Operaciones_basicas_DataFrames.md)
- [Ejecución de consultas SQL](./Modulo2_Fundamentos_Apache_Spark_PySpark/DataFrames_SQL_PySpark/Ejecucion_consultas_SQL.md)
- [Optimización de consultas SQL en Spark](./Modulo2_Fundamentos_Apache_Spark_PySpark/DataFrames_SQL_PySpark/Optimizacion_consultas_SQL_Spark.md)

#### Laboratorio:
- [Cargar un archivo CSV en un DataFrame](./Modulo2_Fundamentos_Apache_Spark_PySpark/DataFrames_SQL_PySpark/Laboratorio_cargar_CSV_DataFrame.md)
- [Realizar operaciones de selección, filtrado y agrupación en el DataFrame](./Modulo2_Fundamentos_Apache_Spark_PySpark/DataFrames_SQL_PySpark/Laboratorio_operaciones_DataFrame.md)
- [Ejecutar consultas SQL en el DataFrame y visualizar los resultados](./Modulo2_Fundamentos_Apache_Spark_PySpark/DataFrames_SQL_PySpark/Laboratorio_SQL_DataFrame.md)
- [Optimizar y ejecutar consultas complejas](./Modulo2_Fundamentos_Apache_Spark_PySpark/DataFrames_SQL_PySpark/Laboratorio_optimizacion_consultas_complejas.md)

#### Recursos:
- [Anexo generador de recursos masivos](./Modulo2_Fundamentos_Apache_Spark_PySpark/DataFrames_SQL_PySpark/generador_recursos.md)

## Módulo 3: Introducción a Python

### Fundamentos de Python

#### Teoría:
- [Historia y evolución de Python](./Modulo3_Introduccion_Python/Fundamentos_Python/Historia_Python.md)
- [Instalación y configuración de Python](./Modulo3_Introduccion_Python/Fundamentos_Python/Instalacion_configuracion_Python.md)
- [Sintaxis básica y estructuras de control](./Modulo3_Introduccion_Python/Fundamentos_Python/Sintaxis_estructuras_control.md)

#### Laboratorio:
- [Escribir y ejecutar scripts básicos en Python](./Modulo3_Introduccion_Python/Fundamentos_Python/Laboratorio_scripts_basicos_Python.md)
- [Uso de estructuras de control (if, for, while)](./Modulo3_Introduccion_Python/Fundamentos_Python/Laboratorio_estructuras_control.md)
- [Trabajar con listas, diccionarios y conjuntos](./Modulo3_Introduccion_Python/Fundamentos_Python/Laboratorio_listas_diccionarios_conjuntos.md)

### Funciones y Módulos en Python

#### Teoría:
- [Definición y uso de funciones](./Modulo3_Introduccion_Python/Funciones_Modulos_Python/Definicion_funciones_Python.md)
- [Módulos y paquetes en Python](./Modulo3_Introduccion_Python/Funciones_Modulos_Python/Modulos_paquetes_Python.md)
- [Gestión de dependencias con pip](./Modulo3_Introduccion_Python/Funciones_Modulos_Python/Gestion_dependencias_pip.md)

#### Laboratorio:
- [Crear y usar funciones en Python](./Modulo3_Introduccion_Python/Funciones_Modulos_Python/Laboratorio_funciones_modulos.md)
- [Importar y usar módulos estándar](./Modulo3_Introduccion_Python/Funciones_Modulos_Python/Laboratorio_importar_modulos.md)
- [Crear y usar paquetes personalizados](./Modulo3_Introduccion_Python/Funciones_Modulos_Python/Laboratorio_paquetes_personalizados.md)

### Manejo de Excepciones y Archivos en Python

#### Teoría:
- [Manejo de excepciones en Python](./Modulo3_Introduccion_Python/Manejo_Excepciones_Archivos_Python/Manejo_excepciones_Python.md)
- [Lectura y escritura de archivos](./Modulo3_Introduccion_Python/Manejo_Excepciones_Archivos_Python/Lectura_escritura_archivos.md)
- [Contextos de manejo de archivos](./Modulo3_Introduccion_Python/Manejo_Excepciones_Archivos_Python/Contextos_manejo_archivos.md)

#### Laboratorio:
- [Implementar manejo de excepciones en scripts](./Modulo3_Introduccion_Python/Manejo_Excepciones_Archivos_Python/Laboratorio_manejo_excepciones_archivos.md)
- [Leer y escribir archivos de texto y CSV](./Modulo3_Introduccion_Python/Manejo_Excepciones_Archivos_Python/Laboratorio_lectura_escritura_archivos.md)
- [Uso de contextos para manejo de archivos](./Modulo3_Introduccion_Python/Manejo_Excepciones_Archivos_Python/Laboratorio_contextos_archivos.md)

## Módulo 4: Trabajando con Azure Databricks Notebooks

### Introducción a los Notebooks de Databricks

#### Teoría:
- [¿Qué es un notebook?](./Modulo4_Azure_Databricks_Notebooks/Introduccion_Notebooks_Databricks/Que_es_Notebook.md)
- [Creación y configuración de notebooks en Databricks](./Modulo4_Azure_Databricks_Notebooks/Introduccion_Notebooks_Databricks/Creacion_configuracion_Notebooks.md)
- [Buenas prácticas en el uso de notebooks](./Modulo4_Azure_Databricks_Notebooks/Introduccion_Notebooks_Databricks/Buenas_practicas_Notebooks.md)

#### Laboratorio:
- [Crear un nuevo notebook en Databricks](./Modulo4_Azure_Databricks_Notebooks/Introduccion_Notebooks_Databricks/Laboratorio_creacion_Notebooks.md)
- [Ejecutar celdas de código básico en Python](./Modulo4_Azure_Databricks_Notebooks/Introduccion_Notebooks_Databricks/Laboratorio_ejecucion_celdas.md)
- [Organización y estructuración de notebooks para proyectos complejos](./Modulo4_Azure_Databricks_Notebooks/Introduccion_Notebooks_Databricks/Laboratorio_estructuracion_Notebooks.md)

### Uso de Python en Notebooks de Databricks

#### Teoría:
- [Escribir y ejecutar código Python](./Modulo4_Azure_Databricks_Notebooks/Uso_Python_Notebooks_Databricks/Escribir_codigo_Python_Notebook.md)
- [Introducción a las celdas mágicas](./Modulo4_Azure_Databricks_Notebooks/Uso_Python_Notebooks_Databricks/Celdas_magicas_Notebook.md)
- [Uso de bibliotecas populares de Python (pandas, numpy, matplotlib)](./Modulo4_Azure_Databricks_Notebooks/Uso_Python_Notebooks_Databricks/Uso_librerias_externas.md)

#### Laboratorio:
- [Escribir funciones Python dentro de un notebook](./Modulo4_Azure_Databricks_Notebooks/Uso_Python_Notebooks_Databricks/Laboratorio_funciones_Python_Notebook.md)
- [Usar celdas mágicas para diferentes propósitos (SQL, Markdown)](./Modulo4_Azure_Databricks_Notebooks/Uso_Python_Notebooks_Databricks/Laboratorio_celdas_magicas.md)
- [Integración de bibliotecas externas y visualización de datos con matplotlib](./Modulo4_Azure_Databricks_Notebooks/Uso_Python_Notebooks_Databricks/Laboratorio_visualizacion_datos.md)

### Ejemplos Básicos en Databricks

#### Teoría:
- [Leer y escribir datos](./Modulo4_Azure_Databricks_Notebooks/Ejemplos_Basicos_Databricks/Lectura_escritura_datos.md)
- [Transformaciones básicas de datos](./Modulo4_Azure_Databricks_Notebooks/Ejemplos_Basicos_Databricks/Transformaciones_basicas_datos.md)
- [Manejo de excepciones y errores en notebooks](./Modulo4_Azure_Databricks_Notebooks/Ejemplos_Basicos_Databricks/Manejo_excepciones_Notebooks.md)

#### Laboratorio:
- [Leer datos desde un archivo CSV](./Modulo4_Azure_Databricks_Notebooks/Ejemplos_Basicos_Databricks/Laboratorio_lectura_CSV.md)
- [Realizar transformaciones simples y guardar los resultados en un nuevo archivo](./Modulo4_Azure_Databricks_Notebooks/Ejemplos_Basicos_Databricks/Laboratorio_transformaciones_datos.md)
- [Uso de logging para seguimiento y depuración](./Modulo4_Azure_Databricks_Notebooks/Ejemplos_Basicos_Databricks/Laboratorio_logging.md)

## Módulo 5: Ingesta y Transformación de Datos

### Cargando Datos en Azure Databricks

#### Teoría:
- [Cargar datos desde Azure Blob Storage y Azure Data Lake Storage](./Modulo5_Ingesta_Transformacion_Datos/Cargando_Datos_Azure_Databricks/Cargar_datos_Azure_Blob_Storage.md)
- [Integración con otras fuentes de datos (bases de datos, APIs)](./Modulo5_Ingesta_Transformacion_Datos/Cargando_Datos_Azure_Databricks/Integracion_fuentes_datos.md)

#### Laboratorio:
- [Conectar Databricks con Azure Blob Storage](./Modulo5_Ingesta_Transformacion_Datos/Cargando_Datos_Azure_Databricks/Laboratorio_conexion_Blob_Storage.md)
- [Leer datos desde un contenedor de Azure Blob Storage](./Modulo5_Ingesta_Transformacion_Datos/Cargando_Datos_Azure_Databricks/Laboratorio_lectura_Blob_Storage.md)
- [Ingesta de datos desde diferentes fuentes (bases de datos, APIs)](./Modulo5_Ingesta_Transformacion_Datos/Cargando_Datos_Azure_Databricks/Laboratorio_ingesta_datos.md)

### Transformación de Datos con PySpark

#### Teoría:
- [Operaciones de transformación](./Modulo5_Ingesta_Transformacion_Datos/Transformacion_Datos_PySpark/Operaciones_transformacion_datos.md)
- [Uso de funciones de usuario (UDFs)](./Modulo5_Ingesta_Transformacion_Datos/Transformacion_Datos_PySpark/Uso_UDFs.md)
- [Optimización de transformaciones de datos](./Modulo5_Ingesta_Transformacion_Datos/Transformacion_Datos_PySpark/Optimizacion_transformaciones.md)

#### Laboratorio:
- [Aplicar transformaciones complejas a un DataFrame](./Modulo5_Ingesta_Transformacion_Datos/Transformacion_Datos_PySpark/Laboratorio_transformaciones_complejas.md)
- [Crear y usar funciones de usuario (UDFs) para transformar datos](./Modulo5_Ingesta_Transformacion_Datos/Transformacion_Datos_PySpark/Laboratorio_UDFs.md)
- [Uso de técnicas avanzadas de optimización de datos (caching, broadcast variables)](./Modulo5_Ingesta_Transformacion_Datos/Transformacion_Datos_PySpark/Laboratorio_optimizacion_datos.md)

### Ejecución de Procesos por Lotes

#### Teoría:
- [Creación de pipelines de procesamiento por lotes](./Modulo5_Ingesta_Transformacion_Datos/Ejecucion_Procesos_Lotes/Creacion_pipeline_lotes.md)
- [Programación y automatización de tareas](./Modulo5_Ingesta_Transformacion_Datos/Ejecucion_Procesos_Lotes/Automatizacion_tareas.md)
- [Mejores prácticas en la gestión de procesos por lotes](./Modulo5_Ingesta_Transformacion_Datos/Ejecucion_Procesos_Lotes/Mejores_practicas_lotes.md)

#### Laboratorio:
- [Crear un pipeline de procesamiento de datos usando notebooks](./Modulo5_Ingesta_Transformacion_Datos/Ejecucion_Procesos_Lotes/Laboratorio_pipeline_lotes.md)
- [Programar la ejecución de notebooks con Databricks Jobs](./Modulo5_Ingesta_Transformacion_Datos/Ejecucion_Procesos_Lotes/Laboratorio_programacion_notebooks.md)
- [Monitoreo y depuración de pipelines de datos](./Modulo5_Ingesta_Transformacion_Datos/Ejecucion_Procesos_Lotes/Laboratorio_monitorizacion_pipelines.md)

## Módulo 6: Análisis de Datos y Machine Learning

### Análisis Exploratorio de Datos (EDA)

#### Teoría:
- [Técnicas de EDA con PySpark](./Modulo6_Analisis_Datos_Machine_Learning/Analisis_Exploratorio_Datos/EDA_PySpark.md)
- [Visualización de datos](./Modulo6_Analisis_Datos_Machine_Learning/Analisis_Exploratorio_Datos/Visualizacion_datos.md)
- [Uso de estadísticas descriptivas en EDA](./Modulo6_Analisis_Datos_Machine_Learning/Analisis_Exploratorio_Datos/Uso_estadisticas_descriptivas.md)

#### Laboratorio:
- [Realizar análisis exploratorio de datos en un conjunto de datos](./Modulo6_Analisis_Datos_Machine_Learning/Analisis_Exploratorio_Datos/Laboratorio_eda_datos.md)
- [Crear gráficos básicos para visualizar datos en Databricks](./Modulo6_Analisis_Datos_Machine_Learning/Analisis_Exploratorio_Datos/Laboratorio_visualizacion_graficos.md)
- [Uso de bibliotecas avanzadas para visualización (seaborn, plotly)](./Modulo6_Analisis_Datos_Machine_Learning/Analisis_Exploratorio_Datos/Laboratorio_seaborn_plotly.md)

### Introducción a MLlib

#### Teoría:
- [¿Qué es MLlib?](./Modulo6_Analisis_Datos_Machine_Learning/Introduccion_MLlib/Que_es_MLlib.md)
- [Algoritmos disponibles en MLlib](./Modulo6_Analisis_Datos_Machine_Learning/Introduccion_MLlib/Algoritmos_disponibles_MLlib.md)
- [Casos de uso de MLlib en proyectos reales](./Modulo6_Analisis_Datos_Machine_Learning/Introduccion_MLlib/Casos_uso_MLlib.md)

## Módulo 7: Optimización y Mejores Prácticas

### Optimización de Consultas y Jobs en Databricks

#### Teoría:
- [Optimización de consultas SQL](./Modulo7_Optimizacion_Mejores_Practicas/Optimizacion_Consultas_Jobs_Databricks/Optimizacion_consultas_SQL.md)
- [Configuración de Spark para rendimiento](./Modulo7_Optimizacion_Mejores_Practicas/Optimizacion_Consultas_Jobs_Databricks/Configuracion_Spark_rendimiento.md)
- [Uso de Spark UI para monitoreo y optimización](./Modulo7_Optimizacion_Mejores_Practicas/Optimizacion_Consultas_Jobs_Databricks/Uso_Spark_UI.md)

#### Laboratorio:
- [Optimizar una consulta SQL compleja](./Modulo7_Optimizacion_Mejores_Practicas/Optimizacion_Consultas_Jobs_Databricks/Laboratorio_optimizacion_consultas.md)
- [Configurar un clúster de Databricks para mejorar el rendimiento](./Modulo7_Optimizacion_Mejores_Practicas/Optimizacion_Consultas_Jobs_Databricks/Laboratorio_configuracion_cluster_rendimiento.md)
- [Uso de técnicas avanzadas de optimización (particionamiento, paralelismo)](./Modulo7_Optimizacion_Mejores_Practicas/Optimizacion_Consultas_Jobs_Databricks/Laboratorio_tecnicas_avanzadas_optimizacion.md)

### Mejores Prácticas en Databricks

#### Teoría:
- [Gestión de clústeres](./Modulo7_Optimizacion_Mejores_Practicas/Mejores_Practicas_Databricks/Gestion_cluster.md)
- [Seguridad y control de acceso](./Modulo7_Optimizacion_Mejores_Practicas/Mejores_Practicas_Databricks/Seguridad_control_acceso.md)
- [Monitoreo y depuración](./Modulo7_Optimizacion_Mejores_Practicas/Mejores_Practicas_Databricks/Monitoreo_depuracion.md)

#### Laboratorio:
- [Implementar controles de acceso y permisos en Databricks](./Modulo7_Optimizacion_Mejores_Practicas/Mejores_Practicas_Databricks/Laboratorio_controles_acceso.md)
- [Configurar alertas y monitoreo de clústeres](./Modulo7_Optimizacion_Mejores_Practicas/Mejores_Practicas_Databricks/Laboratorio_configuracion_alertas.md)
- [Uso de herramientas de monitoreo avanzadas (Azure Monitor, Grafana)](./Modulo7_Optimizacion_Mejores_Practicas/Mejores_Practicas_Databricks/Laboratorio_monitorizacion_grafana.md)


---

## **Requerimientos de Recursos y Permisos para Alumnos**

### **Recursos en Azure (a ser proporcionados por la organización)**

#### **1. Grupo de Recursos en Azure:**
   - **Un grupo de recursos dedicado** para cada alumno, con permisos administrativos completos. El alumno debe poder crear, modificar y eliminar los recursos necesarios para las prácticas.

#### **2. Almacenamiento en Azure:**
   - Provisión de una cuenta de almacenamiento (Azure Blob Storage o Azure Data Lake Storage) dentro del grupo de recursos.
   - El alumno debe tener permisos para:
     - Crear contenedores.
     - Cargar y descargar archivos de datos (CSV, JSON, etc.).
     - Gestionar permisos de acceso a los contenedores de almacenamiento.

#### **3. Azure Databricks Workspace:**
   - Provisión de un **workspace de Azure Databricks** por alumno.
   - Los permisos que deben estar habilitados:
     - Crear y gestionar **clústeres** (incluyendo autoescalado).
     - Crear y ejecutar **notebooks** con PySpark y otras librerías de análisis de datos.
     - Acceso a la **Spark UI** para monitoreo y optimización de trabajos.
     - Lectura y escritura de datos en **Azure Blob Storage** o **Azure Data Lake Storage**.

#### **4. Clúster de Databricks:**
   - Provisión de un clúster en Azure Databricks con:
     - **Mínimo 2 nodos de trabajo** de tipo **DS3 v2** o equivalente.
     - Capacidad de **autoescalado**.
     - Acceso a máquinas virtuales con soporte para **GPU** (opcional para machine learning avanzado).

#### **5. API Pública: OpenWeather**
   - Cada alumno debe contar con una **API Key** personal para consumir la **OpenWeather API**.
     - Clave de API obtenida de: [OpenWeather](https://home.openweathermap.org/users/sign_up).
     - Permisos para realizar llamadas a la API y obtener datos meteorológicos en tiempo real.
     - Endpoint principal: `https://api.openweathermap.org/data/2.5/weather`.
     - Ejemplo de llamada:
       ```bash
       https://api.openweathermap.org/data/2.5/weather?q=London&appid=YOUR_API_KEY
       ```

#### **6. Monitorización y Optimización:**
   - Permisos para acceder y configurar:
     - **Azure Monitor** para la monitorización del rendimiento de clústeres.
     - Visualización de métricas y alertas en **Azure Monitor Dashboards**.

### **Permisos Específicos para Proveer a Cada Alumno:**
   - **Permisos administrativos** sobre su propio grupo de recursos en Azure.
   - **Permisos de propietario** sobre su cuenta de almacenamiento para gestionar sus datos.
   - **Permisos de propietario** sobre su workspace de Azure Databricks para crear y gestionar clústeres y notebooks.
   - **Permisos para realizar consultas a la API de OpenWeather** con su clave personal.

---

## **Requerimientos de Instalación Local en los Equipos de los Alumnos**

Cada alumno deberá tener instalados los siguientes componentes localmente en su equipo para poder realizar las prácticas:

### **1. Instalación de Python:**
   - **Python 3.x** debe estar instalado en su equipo.
   - Las siguientes librerías de Python deben estar instaladas:
     - `pandas`
     - `numpy`
     - `matplotlib`
     - `seaborn`
     - `requests` (para llamadas a APIs externas)

### **2. Acceso a un Navegador Web:**
   - Acceso a un navegador actualizado (Chrome, Firefox, Edge) para acceder al **portal de Azure** y **Azure Databricks**.

### **3. Herramientas de Línea de Comandos (Opcional, para usuarios avanzados):**
   - **Azure CLI** instalada para gestión de recursos en Azure (opcional).
   - **Databricks CLI** para la gestión de clústeres y recursos desde la línea de comandos (opcional).

### **4. Conectividad a Internet:**
   - Acceso a internet con velocidad suficiente para realizar llamadas API, acceder a Databricks, y trabajar con almacenamiento en la nube.

